# RAGの精度を高めるナレッジ設計ガイド

このページでは、別のサイトを使っていますがナレッジの設計の仕方の参考にしてみてください。  
OpenAIのモデルを使用していますので読み替えていただいたり、自分で新しくモデルを追加して挑戦してみましょう。

## 1. ナレッジデータの作成方法

1. [プログラボのWebサイト](https://www.proglab.education/school/)にアクセスし、`ctrl+A`で全選択をしてWebサイトのテキストをコピーします。

2. 生成AI（今回はClaudeを利用）を利用して、ナレッジデータを作成します。以下のようなプロンプトで作成しました。

```
ナレッジデータを作成したいです。

- 各チャンクは500トークン以内に収まるようにしてください。
- チャンクの区切り文字には---を入れてください。
- 各知識をQ&A形式でまとめてください。
- 地域ごとのプログラボの所在地を調べたいので所在地の知識を検索しやすいようにしてください。

（ここにコピーしたサイトのテキストを貼り付ける）

```

```
Difyの親子チャンク用に添付資料のナレッジデータを作成したいです。  
チャンクは ##  
検索は =====  
- 各チャンクは500トークン以内に収まるようにしてください。
- - 各知識をQ&A形式でまとめてください。
```

> <img src="https://i.gyazo.com/c5e6cede3aae1916783df5c979573da7.png" width="450px" />

Difyでの1つのチャンクに入れる情報量の目安が、500トークン（日本語だと300〜400文字程度）です。  
AIが意味を正しく捉えやすいサイズがこれくらいになります。  
タンスの引き出しごとに入れる量を考えるイメージです。


3. 出力されたテキストをxxx.mdというファイルで保存

ファイルの拡張子はDifyが対応している`.md`や`.txt`にしておくと扱いやすいです。

> <img src="https://i.gyazo.com/4c7c110e7081c0481b2d108c27bf494a.png" width="450px" />


## 2.2種類のチャンク設定
AIにナレッジを読ませるとき、同じ文書でもどの部分を検索に使い、どの部分を回答の材料（コンテキスト）に使うかを選べます。  
その方法として、Difyのチャンク設定では、「汎用テキスト分割モード」と「親子分割モード」の2つがあります。  



### 2-1. 汎用テキスト分割モード
> <img src="https://gyazo.com/7644b71b570a40f51fb0b76c6b1cbbf7.png" alt="Image from Gyazo" width="450"/>  

もっともシンプルな分割方法です。  
まずナレッジをチャンクに分割し（ハンズオンでは「---」で区切りました）、必要な情報が書かれているチャンクを見つけて、そのままLLMに渡します。

検索と回答で使うチャンクは同じです。

- **検索に使う文章**：チャンク  
- **回答に使う文章（コンテキスト）**：同じチャンク

つまり **「ひとつのチャンクを、そのまま検索にも回答にも使う」** イメージになります。

**向いているケース**

- FAQのように1問1答の構造がハッキリしている
- 文書が短い、またはシンプル
- まず動くものを作りたいとき

まずは汎用モードで問題ありません。

> <img src="https://i.gyazo.com/bc4521a78653ba9db2fd3cd05cd76187.png" alt="Image from Gyazo" width="450"/>
> 
> <img src="https://i.gyazo.com/4b732eecff34dc645585d8e71123e425.png" alt="Image from Gyazo" width="450"/>


### 2-2. 親子分割モード
> <img src="https://gyazo.com/f86bad34cb3c1d639d9254ab1ae3ac84.png" alt="Image from Gyazo" width="450"/>  

長文や構造が複雑な資料では、汎用モードだと文脈をうまく拾えない場合があります。  
そんなときに活躍するのが **親子分割モード** です。

まず、分割したチャンクをさらに2段階に分けます。

- **大きなチャンク（親）**
- **その中に入る小さなチャンク（子）**

まさに “親子” のような階層構造になります。

次に、検索と回答の使い方が汎用と大きく変わります。

- **検索に使うのは「子チャンク」**  
- **LLMに渡す（回答に使う）のは、その子を含む「親チャンク」**

つまり、

- 細かいチャンクでピンポイントに検索し（子）  
- 見つかった部分に関連する広い文脈（親）をまとめてAIに渡す

という流れになります。

これにより、  
**「検索の精度」と「回答に使う文脈の豊かさ」** の両方が向上すると言われています。

> <img src="https://i.gyazo.com/e27292a679f0e13f5aca951b96f00cbd.png" alt="Image from Gyazo" width="450"/>
> 
> <img src="https://i.gyazo.com/0ddc8dd6e1c4d17a21b0b3719868d01c.png" alt="Image from Gyazo" width="450"/>

実際の設定では、  
- **親チャンク** → `---`  
- **子チャンク** → `\n（改行）`  
のように区切って作ることができます。

> <img src="https://i.gyazo.com/21764ea8a303e837296d53ae4d5c802a.png" alt="Image from Gyazo" width="450"/>

回答精度を高めたいときに、試してみましょう。


## 3. インデックス方法
インデックス方法とは、  
**チャンクを「どのように AI が探しやすい形で保存するか」を決める設定** です。

> <img src="https://gyazo.com/7e770188dd3ed4ba19d1c1bc3322af32.png" alt="Image from Gyazo" width="450"/>

設定をするうえで欠かせないのが、「ベクトル化」と「埋め込みモデル」です。説明してからインデックスの2つのモードを紹介します。

### 3-1. ベクトル化
文章をAIが“意味の近さ”で比べられるように、  
**数値データ（ベクトル）に変換する処理** のことです。

たとえば、

「予約の変更について」  
「予約のキャンセル方法」

この2つは文字は違いますが、内容は近いですよね。

AIはこれを、

“数値として近い” ＝ “内容が似ている”

という形で扱えるようになります。

つまり、ベクトル化することで  
**質問に近い内容のチャンクを見つけられるようになる**  
ということです。


### 3-2. 埋め込みモデルとは？

埋め込みモデルは、  
**文章をベクトル化するための“変換器”** のことです。

Difyで選べる主なモデルは以下の3つです：

- `text-embedding-3-small`（コスパ良い・十分高精度）
- `text-embedding-3-large`（より高精度）
- `text-embedding-ada-002`（旧モデルとの互換用）

このモデルを使うことで、  
チャンクの文章をAIが理解しやすい数値データ（ベクトル）に変換し、どのチャンクが質問に近いかを判断できるようにします。
  
現時点ではどれを選ぶか迷った場合は、まず`text-embedding-3-small`から試すのがおススメです。

> 参考: [新しい埋め込みモデルと API の更新](https://openai.com/ja-JP/index/new-embedding-models-and-api-updates/)


### 3-3. インデックス方法の選択（高品質 / 経済的）

ベクトル化＋埋め込みモデルの説明を踏まえたうえで、  
インデックス方法には次の2種類があります。

#### ■ 高品質（推奨）
埋め込みモデルを使って、  
**文章の意味を考慮した丁寧なベクトル処理を行い、  
チャンク同士の関係がわかりやすい形で保存します。**

- 検索の精度が高くなる  
- LLMの回答が安定しやすい  
- コストは少し高め  

正確性が必要な場合は「高品質」を選びます。

#### ■ 経済的
チャンクごとに **10個のキーワードだけ** を取り出して保存します。  
文章の“意味”までは深く理解しません。

- トークン消費が少なく、コストを抑えられる  
- 検索精度はやや落ちる  

試作段階や、コストを抑えたい場合には候補になります。

## 4. 検索設定
検索方法は3つあり、**「質問に答えるために、どのチャンクをどう探しにいくか」** を設定します。

### 4-1. ベクトル検索（意味で探す）
> <img src="https://gyazo.com/ef19da93b14ffcd3e12900ac19e4f89d.png" alt="Image from Gyazo" width="450"/>

文章の“意味の近さ”でチャンクを探す方法です。

たとえば質問が  
「予約を変えたいのですが」  
だったとき、

- 「予約の変更」
- 「予約のキャンセル方法」

など、**内容が似ているチャンク**を見つけることができます。

埋め込みモデルで作られたベクトル（数値データ）が、ここで活かされます。

### 4-2. 全文検索（文字で探す）
> <img src="https://gyazo.com/affcc38c1c8fb9238b2d22724ffec15c.png" alt="Image from Gyazo" width="450"/>

文字がそのまま一致するチャンクを探す方法です。

- キーワードがそのまま入っていると強い  
- 言い換えや別の表現には弱い  

例：  
「青い本」という文字を含むチャンクだけを探すイメージです。

### 4-3. ハイブリッド検索（いいとこ取り）
> <img src="https://gyazo.com/96cb79f4b6bc9406b9e24a07789b5fca.png" alt="Image from Gyazo" width="450"/>

**ベクトル検索（意味）＋全文検索（文字）** を両方使う方法です。

- 言い換えに強い  
- キーワードにも反応する  
- バランスが良い  

迷ったら **ハイブリッド検索が推奨** です。

#### ウェイト設定（ハイブリッド検索内の調整）

ハイブリッド検索を選んだ場合、  
**どちらの検索を重視するか** を調整できます。

- **意味の近さを重視する** → ベクトル寄り  
- **文字一致を重視する** → 全文寄り  

検索の性質を微調整したいときに利用します。


### 4-4. リランクモデル（結果の並び替え）

リランク（Rerank）とは、文字通り地位や順位を並べ直す（"Re" "Rank"）ことです。  
検索で見つかった複数のチャンクを、  
**「どれが質問に一番近いか」** の順に並び替える仕組みです。

> <img src="https://i.gyazo.com/bad7c60fd2768d666cc250e687d83a34.png" alt="Image from Gyazo" width="450"/>  

> Intelの論文[「LLM Retrieval-Augmented Generation (RAG) with OpenVINO™ and LangChain」](https://www.intel.com/content/dam/develop/public/us/en/documents/langchain-retrieval-augmented-generation-white-paper.pdf)より

検索後の“最終チェック”のような働きをし、  
**`rerank-multilingual-v3-5:0`** が推奨されています。

埋め込みモデルとは役割が異なり、

- **埋め込みモデル**：チャンクをベクトル化する（保存時）  
- **リランクモデル**：検索結果を並び替える（検索時）

という分担になっています。


これらを組み合わせることで、  
AIが必要なチャンクを正しく見つけ、回答の品質が高まります。

---

このページの内容は以上です。  
[◀ 目次ページ](./readme.md)に戻り、全体構成を確認してから講師の指示にしたがって進めましょう。
  


 



